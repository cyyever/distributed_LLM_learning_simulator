---
model_name: hugging_face_causal_lm_Qwen/Qwen3-4B
batch_size: 4
epoch: 1
learning_rate: 2e-4
model_kwargs:
  finetune_config:
    r: 16
    lora_alpha: 64
  finetune_modules:
    - attn.proj
    - qkv
    - self_attn.q_proj
    - self_attn.k_proj
    - self_attn.v_proj
    - self_attn.o_proj
  load_in_4bit: true
  use_gradient_checkpointing: true
