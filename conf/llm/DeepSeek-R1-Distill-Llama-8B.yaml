---
model_name: hugging_face_causal_lm_deepseek-ai/DeepSeek-R1-Distill-Llama-8B
batch_size: 4
epoch: 1
learning_rate: 2e-4
model_kwargs:
  finetune_config:
    r: 16
    lora_alpha: 64
  finetune_modules:
    - q_proj
    - o_proj
    - k_proj
    - v_proj
    - gate_proj
    - up_proj
    - down_proj
  load_in_4bit: true
  use_gradient_checkpointing: true
