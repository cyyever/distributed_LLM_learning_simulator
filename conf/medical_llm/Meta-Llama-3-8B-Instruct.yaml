---
dataset_name: hugging_face_yale_ner
model_name: hugging_face_causal_lm_meta-llama/Llama-3.2-1B-Instruct
optimizer_name: AdamW
batch_size: 8
epoch: 1
use_amp: true
weight_decay: 0
learning_rate: 2e-4
model_kwargs:
  # load_in_8bit: true
  need_finetune: true
  pretrained: true
  finetune_modules:
    # - layers.15.self_attn.q_proj
    # - layers.15.self_attn.k_proj
    # - layers.15.self_attn.v_proj
    # - layers.15.self_attn.o_proj
    # - layers.15.mlp.gate_proj
    # - layers.15.mlp.up_proj
    # - layers.15.mlp.down_proj
    # - layers.15.self_attn.q_proj
    # - layers.15.self_attn.k_proj
    # - layers.15.self_attn.v_proj
    # - layers.15.self_attn.o_proj
    # - layers.15.mlp.gate_proj
    # - layers.15.mlp.up_proj
    # - layers.15.mlp.down_proj
    - q_proj
    - o_proj
    - k_proj
    - v_proj
    - gate_proj
    - up_proj
    - down_proj
dataset_kwargs:
  train_files: ./data/NER_main_train_new.json
  validation_files: ./data/NER_main_train_new.json
  prompt_file: medical.txt
algorithm_kwargs:
  distribute_init_parameters: false
